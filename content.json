{"meta":{"title":"想饮一些酒，让灵魂失重，好被风吹走。","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"links","date":"2020-02-13T15:11:06.000Z","updated":"2021-09-05T07:53:31.746Z","comments":false,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""}],"posts":[{"title":"Light-weight","slug":"Light-weight","date":"2021-09-23T06:20:13.000Z","updated":"2021-09-24T11:27:53.194Z","comments":true,"path":"2021/09/23/Light-weight/","link":"","permalink":"http://example.com/2021/09/23/Light-weight/","excerpt":"","text":"About Light-Weight这篇主要来总结和了解一下关于轻量化网络设计的一些知识。 基本概念 感受野（Receptive Field） 指的是每一层输出的特征图（feature map）上每个像素点映射回输入图像上的区域大小。范围越大，就代表能够学习到更加全局、层次更高的特征，相反的是，范围越小说明能够学到局部的细节。所以网络越深，感受野越大。 深度（Depth） 一般来说，深度决定了网络的表达能力，早期的backbone通过堆叠卷积层的方法，后期通过module堆叠的方法。通常越深的网络表达能力越强，但也可能有副作用，所以需要调参！ 宽度（Width） 宽度决定了某一层学到的信息量，但网络的宽度时指的是最大的通道数，有卷积核数量最多的层决定。通常在最后一层feature map达到最大，因为分辨率越小，包含的信息越高级，通道越多效果越好。但是计算量会他别打，通常通道数按照8的倍数来决定。 分辨率（Resolution） 指的是输入模型的图像尺寸，通常情况会根据模型下采样次数$N$和最后一次下采样后feature map的分辨率$k\\times k$来决定输入分辨率大小，即$r = k\\times2^{n}$ 分组卷积（Group convolution） 最早提出在AlexNet中，那时GPU的性能还不支持全部卷积同时操作，所以作者提出把feature map分给多个GPU进行处理，最后再融合。如下图： 图中输入的数据再深度上被分成的g组，具体的数量由$(C1/g)$决定，相应的每一组的卷积核的深度也变成了$(C1/g)$，每一组的个数变成了$(C2/g)$。最后通过concat进行组合。例如输入为256，输出为256，$kernel size = 3\\times3$，普通卷积的参数量为$256\\times3\\times3\\times256$，若g=8，则参数量变为$8\\times32\\times3\\times3\\times32$，减少了8倍。 经典模型VGG原论文如下说到 So what have we gained by using, for instance, a stack of three $3\\times3$ conv. layers instead of a single $7\\times7$ layer? First, we incorporate three non-linear rectifification layers instead of a single one, which makes the decision function more discriminative. Second, we decrease the number of parameters: assuming that both the input and the output of a three-layer $3\\times3$ convolution stack has C channels, the stack is parametrised by $3(3^{2}C^{2})$ = 27$C^{2}$ weights; at the same time, a single $7\\times7$ conv. layer would require $7^{2}C^{2}$ = 49$C^{2}$ parameters 从轻量化角度来说，利用$3\\times3$的卷积核来代替其他的卷积核，在拥有相同感受野的情况下，能够做到参数量小的优点。 MobileNet系列ShuffleNet系列GhostNet","categories":[],"tags":[]},{"title":"FCOS","slug":"FCOS","date":"2021-09-16T04:40:23.000Z","updated":"2021-09-17T06:28:27.844Z","comments":true,"path":"2021/09/16/FCOS/","link":"","permalink":"http://example.com/2021/09/16/FCOS/","excerpt":"","text":"FCOS: Fully Convolutional One-Stage Object Detection​ FCOS是一个基于FCN（全卷积网络）、一阶段（one stage）、anchor free、参考语义分割实现逐像素的单阶段目标检测。原论文地址. 摘要 We propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to semantic segmentation. Almost all state-of-the-art object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box free, as well as proposal free. By eliminating the predefined set of anchor boxes, FCOS completely avoids the complicated computation related to anchor boxes such as calculating overlapping during training. More importantly, we also avoid all hyper-parameters related to anchor boxes, which are often very sensitive to the final detection performance. With the only post-processing non-maximum suppression (NMS), FCOS with ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale testing, surpassing previous one-stage detectors with the advantage of being much simpler. For the first time, we demonstrate a much simpler and flexible detection framework achieving improved detection accuracy. We hope that the proposed FCOS framework can serve as a simple and strong alternative for many other instance-level tasks 介绍 FCOS方法借鉴了FCN的思想，在每个feature map上的特征点做回归操作，预测（l，r，t，d）四个值，代表了到GTBox的上、下、左、右的距离。 引入了FPN结构，利用不同的层来处理不同尺寸的目标框。 引入了Centerness Layer来增强中心点选取的准确性 分类损失focal loss；回归损失iou loss；centerness损失BCE 方法Anchor-based的缺点 anchor-base模型的检测性能一定程度上依赖于anchor的设计，anchor的基础尺寸、长宽比、以及每一个特征点对应的anchor数目等。比如Faster提出的基准anchor大小16，3种倍数[8, 16, 32] 以及三种比例，共9种anchor。 设定好anchor了只能说是匹配到大部分目标，对于那些形变较大的目标检测起来还是比较困难，同时这也一定程度上限制了模型的泛化能力。 为了取得较好的召回率，那就需要为每个特征点安排更密集的anchor，在前向推演以及NMS等操作时，显存以及CPU消耗很大。 在这些放置的更密集的anchor中，大多数anchor属于负样本，这样也造成了正负样本之间的不均衡。（Faster好像各选128 positive / negtive 作为训练anchor，不过肯定不是随机挑选的） 模型结构下图是FCOS的模型结构： 整体还是非常传统的Bckbone+FPN+head结构 论文中的一些定义 第i个GTbox的定义为：$B_{i}$,其中$(x_{0}^{(i)},y_{0}^{(i)})$，$(x_{1}^{(i)},y_{1}^{(i)})$表示的是当前Bbox左上角和右下角的坐标。 回归分支预测的为当前点$(X,Y)$到GTBox边界的距离$(l,r,t,d)$，真实标签定义为$(l^{*},r^{*},t^{*},d^{*})$。值如下计算： 映射回的点如果在一个GTBox内就归为正样本，类别为BBOX内的目标类别，其余归为负样本。 按照s(下采样总倍数)将特征点映射回原图，参照公式 (x^{'},y^{'}) = (floor(\\frac{s}{2}) + xs, floor(\\frac{s}{2}) + ys)\\tag1特征点上的点为$(x,y)$，原图位置为$(x^{‘},y^{‘})$ FPN当一个$(x^{‘’},y^{‘’})$落在多个GTBox中，该论文将该特征点称为模糊样本，论文中说道： If a location falls into multiple bounding boxes, it is considered as an ambiguous sample.We simply choose the bounding box with minimal area as its regression target. 论文简单的选择面积更小的GTBox做为回归目标。 与anchor-based的模型不同，FCOS选择了设置阈值来限制每一层feature map的回归范围。具体操作如下 首先计算出不同层级feature map上每个特征点对应的回归目标$(l^{*},r^{*},t^{*},d^{*})$ 如果特征点满足$max((l^{*},r^{*},t^{*},d^{*})&gt;m_{i})max((l^{*},r^{*},t^{*},d^{*})&lt;m_{i-1})$，将该样本认定为负样本。 m_{i}表示为第i层feature map回归的做大距离，本文设置了$(m_{2},m_{3},m_{4},m_{5},m_{6},m_{7} = 0,64,128,258,512,\\infty)$，例如p3回归的范围为[0,64]，p4范围就为[64,128] 如果回归在了两个GTBox里，就要分为两种情况 假定一个格子表示16px，A距离紫色边界的最大距离为48px，距离绿色的最大距离为90px，根据p3的范围，对应的是紫色框，如果没有GTBox，就为负样本。 如果一个格子表示8px，那么A距离紫色边界最大距离为24px，距离绿色最大距离为40px，在都符合要求的情况下选择面积更小的作为回归目标 Center-ness Layer​ 由于一个特征点映射到原图的时候可能位于GTBox的边缘或者距离中心较远的位置，因此在模型学习的时候可能会认为这个点不属于它本该的目标，导致了出现新的box。 ​ 为了解决这个问题，提出了中心度的思想，告诉哪些点是目标最可能的中心点（告诉某些点不是中心点）。 ​ 将目标中心点的值设定为1，距离越远该值就越趋近于0。真实值标签计算方法如下公式所示： centerness^{*} = \\sqrt{\\frac{min(l^{*},r^{*})}{max(l^{*}{r^{*}})}\\times\\frac{min(t^{*},b^{*})}{max(t^{*},b^{*})}}\\tag2​ 这部分的损失使用BCE损失。 ​ 模型的最终输出是一组置信度高的box和类别，然后使用NMS进行抑制筛选。模型的最终输出置信度=(类别的概率)*(对应的center-ness)。 ​ center-ness会让模型更加关注到距离真实目标中心点近的预测box。 ​ 下图的实验证明了这样的相乘是有意义的，置信度越高预测出来的box和GTBox的IOU越高。 ​ 损失函数 分类损失，弃用了softmax，对head输出的分类的每一个通道分别使用sigmoid函数，最后使用Focal loss来计算。 回归损失：IOU Loss，对有意义的特征点进行回归，$c^{*}_{x,y}=0$ 就是不在一个GTBox的对应点，为负样本。如果在一个或者多个box，根据阈值重复筛选直到有意义即$c^{*}_{x,y}&gt;0$ center-ness损失：BCE损失，为什么没有在论文公式图里？？？？ 细节​ 在引入FPN的同时还引入一些改变，FCOS在不同的特征层级之间共享head（共享的是结构/权重共享 ）。但是不同的特征层级需要回归不同的大小范围（例如，P3的大小范围是[0，64]，P4的大小范围是[64，128]，因此对于不同的特征层级使用相同的head是不合理的。因此，论文中不再使用标准的$exp(x)$，而是使用$exp( s_{i}* x)$，其中可训练标量 被用来自动调整不同层级特征的指数函数的基数，从而稍微提高了检测性能 总结 可以引入一些提升性能的trick，比如GN，可变性卷积等 实现了proposal free 和 anchor free，避免了复杂的iou计算了匹配，（但是翻了一下别人的博客说用特征分布有差异的数据集训练普适性不是很好。 修改一下可以做实例分割、关键点检测等","categories":[],"tags":[]},{"title":"Introduction","slug":"Introduction","date":"2021-09-12T07:45:51.000Z","updated":"2021-09-12T11:21:56.826Z","comments":true,"path":"2021/09/12/Introduction/","link":"","permalink":"http://example.com/2021/09/12/Introduction/","excerpt":"","text":"Welcome to my blog！欢迎来到我的博客，在浏览我的博客之前，希望你可以先看一下一些introduction以便你更好得了解我。 关于我的博客这是Mr.ind1fferent的博客，通过github+hexo搭建完成，使用的是sakura主题（很多还没有配完，待完善，也不知道要不要完善：） 至于为什么要叫Mr.ind1fferent，是因为高中英语李老师和我聊天的时候根据我的名字给我取的，至今令我印象深刻。 为什么要写博客 做为计算机的学生，我觉得不仅仅是要把本科的学完，课上传授的知识不够你本科毕业去寻找工作，写博客可以把你在课余时间学习到的知识记录下来，提供你学习的动力 博客也是一种记录你生活的一个方式，慢慢得积累下去，你会怀念这段时光。 博客能够更好地帮助你理解你所学的知识，希望所有计算机地学子们能够不忘初心。 一些闲话 博客的一些相关配置还没有完全弄好（会尽快！），最近应该会把时间放在写博客上面 由于能力有限，我会尽我所能把我阅读的论文正确地分享给大家，一些比较久远的论文可能就会大概地讲一下。 深度学习的代码大部分会基于pytorch，但不排除有些会用paddlepaddle和mindspore 关于深度学习很多刚接触这方面的小白，可能会觉得深度学习非常的高深莫测，实际上并不全是。 从2020年底学习深度学习（下文简称“DL”）到现在，有一些体会想分享给大家。 打好基础 众所周知现在DL都会建立在python这门语法，学好基础的语法知识有助于理解 不要放弃 在刚开始入门时，你会接触到很多的数学公式，这可能对一些同学不是很友好，确实DL的理论学习刚开始是非常困难的。 提高英语水平 在学习DL的过程中，避免不了地会遇到许多专业名词和论文阅读，这需要你有一定的英语基础。 进实验室或者社团 一般的电脑并不支持DL的训练任务，这时候就需要你进入实验室或者社团，利用这里的硬件资源，这样你有新的idea的时候也比较容易去实现 关于比赛心得 首先不要认为你的技术不够或者很多东西没有学而畏惧比赛，基本上所有人都是边比赛边学习。 不要报着功利的态度去参加比赛 尽量选择一些能够用在多项比赛的项目，一举多得","categories":[],"tags":[]},{"title":"各类激活函数介绍","slug":"各类激活函数介绍","date":"2021-09-06T13:12:14.000Z","updated":"2021-09-08T05:18:23.778Z","comments":true,"path":"2021/09/06/各类激活函数介绍/","link":"","permalink":"http://example.com/2021/09/06/%E5%90%84%E7%B1%BB%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"什么是激活函数？激活函数(Activation functions)对于神经网络模型去学习、理解复杂和非线性的函数具有十分重要的作用。将非线性特性引入到网络当中。 如下图的网络图 那到底网络是通过什么操作来的到最后一个节点的输出呢？没错，就是激活函数。 为什么要使用激活函数？ 激活函数对模型学习和理解有着重要的作用 激活函数提供非线性的因素。如果不使用，只是输出了一个简单的线性函数，复杂度十分有限，从数据中学习复杂函数的映射能力有限，神经网络将无法学习和模拟其他复杂类型的数据，例如语音、视频、图像等等 激活函数能够把特征空间通过一定的线性映射转换到另一个空间，能够更好地被分类。 常用的激活函数 sigmoid激活函数函数的定义方程如下图 f(x) = \\frac{1}{1+e^{-x}}值域为(0,1)。函数图像如下 优点：它能够将输入的连续值变为0和1之间的输出，如果是非常大的负数，输出就是0；非常大的正数，输出就是1。 缺点：1.容易在反向传播时导致梯度爆炸和梯度消失（直接上超链接了以后有空写）。函数的导数如下图： ​ 2.不是以0为对称轴 函数及其导数的代码参考实现如下： 12345678910111213141516171819202122232425262728293031import numpy as npimport matplotlib.pyplot as plt# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef d_sigmoid(x): y = 1 / (1 + np.exp(-x)) dy = y * (1 - y) return dydef sigmoid(x): y = 1 / (1 + np.exp(-x)) return ydef plot_sigmoid(): # param:起点，终点，间距 x = np.arange(-8, 8, 0.2) plt.subplot(1, 2, 1) plt.title('sigmoid') # 第一幅图片标题 y = sigmoid(x) plt.plot(x, y) plt.subplot(1, 2, 2) y = d_sigmoid(x) plt.plot(x, y) plt.title(import numpy as npimport matplotlib.pyplot as plt# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef d_sigmoid(x): y = 1 / (1 + np.exp(-x)) dy = y * (1 - y) return dydef sigmoid(x): y = 1 / (1 + np.exp(-x)) return ydef plot_sigmoid(): # param:起点，终点，间距 x = np.arange(-8, 8, 0.2) plt.subplot(1, 2, 1) plt.title('sigmoid') # 第一幅图片标题 y = sigmoid(x) plt.plot(x, y) plt.subplot(1, 2, 2) y = d_sigmoid(x) plt.plot(x, y) plt.title('sigmoid导数') plt.show() tanh激活函数函数的定义方程如下图： tanh(x) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}值域为(-1,1)。函数图像如下： ​ 导数如下： ​ ​ 该函数解决了Sigmoid函数不是zero-centered输出问题，然后梯度消失问题和幂运算的问题仍然存在。 ​ 优点： ​ 1.解决了Sigmoid的输出不关于零点对称的问题 ​ 2.也具有Sigmoid的平滑、容易求导的优点 ​ 缺点： ​ 1.运算量过大 ​ 2.梯度消失没有解决 ​ 函数及其导数的代码参考实现如下： ​ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef tanh(x): \"\"\"tanh函数\"\"\" return ((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))def dx_tanh(x): \"\"\"tanh函数的导数\"\"\" return 1 - tanh(x) * tanh(x)if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = tanh(x) dx_fx = dx_tanh(x) plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('tanh 函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('tanh函数的导数') plt.xlabel('x') plt.ylabel(from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef tanh(x): \"\"\"tanh函数\"\"\" return ((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))def dx_tanh(x): \"\"\"tanh函数的导数\"\"\" return 1 - tanh(x) * tanh(x)if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = tanh(x) dx_fx = dx_tanh(x) plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('tanh 函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('tanh函数的导数') plt.xlabel('x') plt.ylabel('dx_fx') plt.plot(x, dx_fx) plt.show() Relu激活函数受到了step函数的生物学启发，当输入为正的时候，导数不为零，允许基于梯度的学习。在输入为负值的时候，学习速度会变得很慢。函数的定义为： f(x) = max(0,x)函数图像如下： 函数的导数如下： 优点：1.相比于Sigmoid和tanh函数，ReLU在SGD中能够快速收敛，它具有线性、非饱和的形式 ​ 2.有效缓解了梯度消失的问题 ​ 3.SIgmoid和tanh设计了很多expensive的操作，ReLU可以更加简单的实现。 ​ 4.无监督预训练能有较好的表现 缺点： ​ 1.输出不是zero-centered ​ 2.死亡ReLU（Dead ReLU Problem），某些神经元可能永远不会被激活，导致参数不会被更新。 ​ 尽管存在这两个问题，ReLU仍然是最常用的激活函数，在搭建人工神经网络的时候推荐大家优先尝试！ 函数及导数代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef relu(x): \"\"\"relu函数\"\"\" # temp = np.zeros_like(x) # if_bigger_zero = (x &gt; temp) # return x * if_bigger_zero return np.where(x &lt; 0, 0, x)def dx_relu(x): \"\"\"relu函数的导数\"\"\" # temp = np.zeros_like(x) # if_bigger_equal_zero = (x &gt;= temp) # return if_bigger_equal_zero * np.ones_like(x) return np.where(x &lt; 0, 0, 1)# ---------------------------------------------if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = relu(x) dx_fx = dx_relu(x) plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Relu函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Relu函数的导数') plt.xlabel('x') plt.ylabel(from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef relu(x): \"\"\"relu函数\"\"\" # temp = np.zeros_like(x) # if_bigger_zero = (x &gt; temp) # return x * if_bigger_zero return np.where(x &lt; 0, 0, x)def dx_relu(x): \"\"\"relu函数的导数\"\"\" # temp = np.zeros_like(x) # if_bigger_equal_zero = (x &gt;= temp) # return if_bigger_equal_zero * np.ones_like(x) return np.where(x &lt; 0, 0, 1)# ---------------------------------------------if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = relu(x) dx_fx = dx_relu(x) plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Relu函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Relu函数的导数') plt.xlabel('x') plt.ylabel('dx_fx') plt.plot(x, dx_fx) plt.show() Leaky ReLU函数（PReLU）函数的定义为 f(x) = max(ax,x)函数的图像如下： ​ 函数的导数如下： ​ ​ 特点：与ReLU相比，Leak给所有负值赋予了一个非零斜率，leak是一个很小的常数，保留了一些负轴的值，使得负轴的信息不会全部丢失。 ​ 函数及其导数代码如下： ​ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif']= ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef leaky_relu(x): \"\"\"leaky relu函数\"\"\" return np.where(x &lt; 0, 0.01 * x, x)def dx_leaky_relu(x): \"\"\"leaky relu函数的导数\"\"\" return np.where(x &lt; 0, 0.01, 1)# ---------------------------------------------if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = leaky_relu(x) dx_fx = dx_leaky_relu(x) plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Leaky ReLu函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Leaky Relu函数的导数') plt.xlabel('x') plt.ylabel(from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif']= ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef leaky_relu(x): \"\"\"leaky relu函数\"\"\" return np.where(x &lt; 0, 0.01 * x, x)def dx_leaky_relu(x): \"\"\"leaky relu函数的导数\"\"\" return np.where(x &lt; 0, 0.01, 1)# ---------------------------------------------if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = leaky_relu(x) dx_fx = dx_leaky_relu(x) plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Leaky ReLu函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Leaky Relu函数的导数') plt.xlabel('x') plt.ylabel('dx_fx') plt.plot(x, dx_fx) plt.show() Mish激活函数函数定义如下 f(x) = x*tanh(ln(1+e^{x}))函数图像如下： 函数的导数如下： 函数特点： 1.无上界、有下界、平滑且非单调 优点： 1.防止了梯度消失 2.提升了网络的正则化效果 3.减少了一些不可预料的问题，使得网络更容易优化并且提高泛化性能。 缺点： 1.引入了指数函数，增加了计算量 函数及其导数代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef sech(x): \"\"\"sech函数\"\"\" return 2 / (np.exp(x) + np.exp(-x))def sigmoid(x): \"\"\"sigmoid函数\"\"\" return 1 / (1 + np.exp(-x))def softplus(x): \"\"\"softplus函数\"\"\" return np.log10(1 + np.exp(x))def tanh(x): \"\"\"tanh函数\"\"\" return ((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = x * tanh(softplus(x)) dx_fx = sech(softplus(x)) * sech(softplus(x)) * x * sigmoid(x) + fx / x plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Mish函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Mish函数的导数') plt.xlabel('x') plt.ylabel(from matplotlib import pyplot as pltimport numpy as np# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falsedef sech(x): \"\"\"sech函数\"\"\" return 2 / (np.exp(x) + np.exp(-x))def sigmoid(x): \"\"\"sigmoid函数\"\"\" return 1 / (1 + np.exp(-x))def softplus(x): \"\"\"softplus函数\"\"\" return np.log10(1 + np.exp(x))def tanh(x): \"\"\"tanh函数\"\"\" return ((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))if __name__ == '__main__': x = np.arange(-10, 10, 0.01) fx = x * tanh(softplus(x)) dx_fx = sech(softplus(x)) * sech(softplus(x)) * x * sigmoid(x) + fx / x plt.subplot(1, 2, 1) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Mish函数') plt.xlabel('x') plt.ylabel('fx') plt.plot(x, fx) plt.subplot(1, 2, 2) ax = plt.gca() # 得到图像的Axes对象 ax.spines['right'].set_color('none') # 将图像右边的轴设为透明 ax.spines['top'].set_color('none') # 将图像上面的轴设为透明 ax.xaxis.set_ticks_position('bottom') # 将x轴刻度设在下面的坐标轴上 ax.yaxis.set_ticks_position('left') # 将y轴刻度设在左边的坐标轴上 ax.spines['bottom'].set_position(('data', 0)) # 将两个坐标轴的位置设在数据点原点 ax.spines['left'].set_position(('data', 0)) plt.title('Mish函数的导数') plt.xlabel('x') plt.ylabel('dx_fx') plt.plot(x, dx_fx) plt.show() 总结​ 在深度学习的发展中，出现了许多的激活函数，那么我们改如何选择激活函数呢？ ​ 1.由于需要花费大量时间来处理大量数据，收敛的速度尤其重要。所以尽量要使用zero-centered数据和zero-centered输出，加快收敛速度。 ​ 2.如果使用了ReLU，一定要注意学习率的设置，或者你可以尝试Leaky ReLU或者PReLU等等 ​ 3.sigmoid做为远古的激活函数，已经很少被使用！ ​ （忘了softmax，如果我还记得的话会补上","categories":[],"tags":[]},{"title":"MGN_net","slug":"MGN-net","date":"2021-09-06T04:34:02.000Z","updated":"2021-09-24T14:19:01.495Z","comments":true,"path":"2021/09/06/MGN-net/","link":"","permalink":"http://example.com/2021/09/06/MGN-net/","excerpt":"","text":"Learning Discriminative Features with Multiple Granularities for Person Re-Identification这是一篇关于行人重识别的笔记，学习了云从科技的MGN网络。原论文：Learning Discriminative Features with Multiple Granularities for Person Re-Identification 摘要：The combination of global and partial features has been an essential solution to improve discriminative performances in person re-identification(Re-ID)tasks. Previous part-based methods mainly focus on locating regions with specific pre-defined semantics to learn local representations, which increases learning difficulty but not efficient or robust to scenarios with large variances In this paper, we propose an end-to-end feature learning strategy integrating discriminative information with various granularities We carefully design the Multiple Granularity Network(MGN),a multi-branch deep network architecture consisting of one branch for global feature representations and two branches for local feaure representations. Instead of learning on semantic regions, we uniformly partition the images into several stripes, and vary the number of parts in different local branches to obtain local feature representations with multiple granularities. Comprehensive experiments implemented on the mainstream evaluation datasets including Market-1501, Duke MTMC-reid and CUHKO3 indicate that our method robustly achieves state-of-the -art performances and outperforms any existing approaches by a large margin For example, on Market-1501 dataset in single query mode, we obtain a top result of Rank-1/mAP=96.6%/94.2% with this method after re-ranking。 介绍本文提出了一种网络结构，将全局特征跟多粒度局部特征结合在一起，全局特征负责整体的宏观上大家共有的特征的提取，然后把图像切分成不同块，每一块不同粒度，负责不同层次或者不同级别特征的提取。在观察中发现，确实随着分割力度的增加，模型能够学到更详细的细节，最终产生MGN的网络结构。 相关工作 表征学习：通过设计分类损失与对比损失，实现对网络的监督学习。 度量学习：基于TripletLoss三元损失的ReID方案。 局部特征学习：基于局部区域调整的ReID解决方案。 方法 多粒度特征：上图第一列有3张图，中间一列把3张图二分之一上下均分，第三列是把人从上到下分成三块——头部、腹部、腿部，它有3个粒度，每个粒度做独立的引导，使得模型尽量对每个粒度学习更多信息。 下图表示的是注意力的呈现效果，这不是基于本模型产生的，是基于之前的算法看到的。上面的图是整张图在输入时网络在关注什么，整个人看着比较均匀，范围更广。第三栏从上到下相当于切成3块，每一块看的时候它的关注点会更加集中一点，亮度分布不会像上图那么均匀，更关注局部的亮点，可以理解为网络在关注不同粒度的信息。 网络结构： 如下图，输入的尺寸为 384×128，用的backbone为ResNet-50，如果在不做任何改变的情况下，它的特征图谱输出尺寸，从下方表格可以看到，global 这个地方就相当于对 Resnet 50不做任何的改变，特征图谱输出是 12×4。 下面有一个 part-2 跟 part-3，这是在 Res4_1 的位置，本来是有一个stride 等于 2 的下采样的操作，我们把 2 改成 1，没有下采样，这个地方的尺寸就不会缩小 2，所以 part-2 跟 part-3 比 global 大一倍的尺寸，它的尺寸是 24×8。为什么要这么操作？因为会强制分配 part-2 跟 part-3 去学习细粒度特征，如果把特征尺寸做得大一点，相当于信息更多一点，更利于网络学到更细节的特征。 网络结构从左到右，先是两个人的图片输入，这边有 3 个模块。3 个模块的意思是表示 3 个分支共享网络，前三层这三个分支是共享的，到第四层时分成三个支路，第一个支路是 global 的分支，第二个是 part-2 的分支，第三个是 part-3 的分支。在 global 的地方有两块，右边这个方块比左边的方块大概缩小了一倍，因为做了个下采样，下面两个分支没有做下采样，所以第四层和第五层特征图是一样大小的。 接下来我们对 part-2 跟 part-3 做一个从上到下的纵向分割，part-2 在第五层特征图谱分成两块，part-3 对特征图谱从上到下分成三块。在分割完成后，我们做一个 pooling，相当于求一个最值，我们用的是 Max-pooling，得到一个 2048 的向量，这个是长条形的、横向的、黄色区域这个地方。 但是 part-2 跟 part-3 的操作跟 global 是不一样的，part-2 有两个 pooling，第一个是蓝色的，两个 part 合在一起做一个 global-pooling，我们强制 part-2 去学习细节的联合信息，part-2 有两个细的长条形，就是刚才引导它去学细节型的信息。淡蓝色这个地方变成小方体一样，是做降维，从 2048 维做成 256 维，这个主要方便特征计算，因为可以降维，更快更有效。在测试的时候会在淡蓝色的地方，小方块从上到下应该是 8 个，我们把这 8 个 256 维的特征串连一个 2048 的特征，用这个特征替代前面输入的图片。 ​ Loss设计：Loss说简单也简单，说复杂也复杂。从头到尾就用了两种Loss，一个是SoftmaxLoss，一个是TripletLoss(这两个Loss有空写一下现在就将就放个链接)。 分别如下两图所示 L_{softmax} = -\\sum_{i=1}^{N}log\\frac{e^{w^{T}_{yi}}f_{i}}{\\sum_{k=1}^{C}e^{w^{T}_{k}}f_{i}}\\tag 1 L_{triplet}=-\\sum_{i=1}^{p}\\sum_{a=1}^{k}[a+\\underset{p=1...k}{max}||f_{a}^{(i)}-f_{p}^{(i)}||_{2}-\\min_{n=1...K\\\\j=1...P }||f_{a}^{(i)}-f_{=n}^{(i)}||_{2}]\\tag 2在global分支上，对2048维做了SoftmaxLoss，对256维做了TripletLoss，这是对global信息通用的方法。下面两个部分global的处理方式也是一样的。中间part-2有一个全局信息，做两个Loss。 但是，下面两个 Local 特征看不到 TripletLoss，只用了 SoftmaxLoss，如果对细节当和分支做 TripletLoss，效果会变差。为什么效果会变差？ 一张图片分成从上到下两部分的时候，最完美的情况当然是上面部分是上半身，下面部分是下半身，但是在实际的图片中，有可能整个人都在上半部分，下半部分全是背景，这种情况用上、下部分来区分，假设下半部分都是背景，把这个背景放到 TripletLoss 三元损失里去算这个 Loss，就会使得这个模型学到莫名其妙的特征。 比如背景图是个树，另外一张图是某个人的下半身，比如一个女生的下半身是一个裙子，你让裙子跟另外图的树去算距离，无论是同类还是不同类，算出来的距离是没有任何物理意义或实际意义的。从模型的角度来讲，它属于污点数据，这个污点数据会引导整个模型崩溃掉或者学到错误信息，使得预测的时候引起错误。 总结​ 在使用SGD momentum=0.9，Learning rate=0.01的情况下，做了weight decay = 0.0005，分别在第40个epoch和第60个epoch，在Market1501训练80个epochs，Rank1达到了95.7%，mAP为86.9%。 ​ 对一些已知测试集数据分布的情况下，可以用ReRank技术把指标大大提高。 ​ 基于paddlepaddle深度学习框架的代码已复现，并开源至https://github.com/Mr-ind1fferent/Re-ID_MGN_Paddlepaddle","categories":[],"tags":[]},{"title":"","slug":"ReID_MGN_Paddlepaddle","date":"2021-08-23T11:04:48.792Z","updated":"2021-09-01T08:22:20.639Z","comments":true,"path":"2021/08/23/ReID_MGN_Paddlepaddle/","link":"","permalink":"http://example.com/2021/08/23/ReID_MGN_Paddlepaddle/","excerpt":"","text":"Re-ID_MGN_PaddlepaddleThe codeDependencies: PaddlePaddle==2.1 Data:The data structure will be like: 123456data/ bounding_box_test/ bounding_box_train/ gt_bbox/ gt_query/ query/ Market1501You can download dataset from here . The password is : RWZW WeightsThe weights we have already trained can be download here .The password is : jam3 Train1python main.py --mode train --data_path &lt;path/to/Market-1501-v15.09.python main.py --mode train --data_path &lt;path/to/Market-1501-v15.09.15> You can find more parameters in opt.py EvaluateYou can use our weight or your trained weight 1python main.py --mode evaluate --data_path &lt;path/to/Market-1501-v15.09.15&gt; --weight &lt;path/python main.py --mode evaluate --data_path &lt;path/to/Market-1501-v15.09.15&gt; --weight &lt;path/to/weight_name.pdparams> Visualize1python main.py --mode vis --query_image &lt;path/to/query_image&gt; --weight &lt;path/python main.py --mode vis --query_image &lt;path/to/query_image&gt; --weight &lt;path/to/weight_name.pdparams> Visualize rank10 query result from bounding_box_test","categories":[],"tags":[]}],"categories":[],"tags":[]}